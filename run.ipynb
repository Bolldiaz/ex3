{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\OneDrive\\huji\\2023A\\NLP\\ex3\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "from exercise_blanks import *\n",
    "n_epochs = 10\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = LSTM(embedding_dim=W2V_EMBEDDING_DIM, hidden_dim=100, n_layers=1, dropout=.5)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_manager = None\n",
    "# with open('data_manager.obj', 'wb') as fp:\n",
    "     # data_manager = DataManager(W2V_SEQUENCE, batch_size=BATCH_SIZE, embedding_dim=W2V_EMBEDDING_DIM)\n",
    "     # pickle.dump(data_manager, fp)\n",
    "with open('data_manager.obj', 'rb') as fp:\n",
    "    data_manager = pickle.load(fp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --------- Starting epoch 0/4 --------- #\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# training\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m performances \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mdata_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0001\u001B[39;49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                           \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\huji\\2023A\\NLP\\ex3\\exercise_blanks.py:422\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, data_manager, criterion, n_epochs, lr, weight_decay)\u001B[0m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[0;32m    420\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# --------- Starting epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m --------- #\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 422\u001B[0m     loss, accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_iterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    423\u001B[0m     t_loss\u001B[38;5;241m.\u001B[39mappend(loss), t_acc\u001B[38;5;241m.\u001B[39mappend(accuracy)\n\u001B[0;32m    425\u001B[0m     loss, accuracy \u001B[38;5;241m=\u001B[39m evaluate(model, validation_iterator, criterion)\n",
      "File \u001B[1;32m~\\OneDrive\\huji\\2023A\\NLP\\ex3\\exercise_blanks.py:366\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, data_iterator, optimizer, criterion)\u001B[0m\n\u001B[0;32m    363\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    365\u001B[0m     train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(loss)\n\u001B[1;32m--> 366\u001B[0m     train_correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m binary_accuracy(predicted_labels, true_labels, normalized\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m train_loss \u001B[38;5;241m/\u001B[39m samples_num, train_correct \u001B[38;5;241m/\u001B[39m samples_num\n",
      "File \u001B[1;32m~\\OneDrive\\huji\\2023A\\NLP\\ex3\\exercise_blanks.py:366\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, data_iterator, optimizer, criterion)\u001B[0m\n\u001B[0;32m    363\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    365\u001B[0m     train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(loss)\n\u001B[1;32m--> 366\u001B[0m     train_correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m binary_accuracy(predicted_labels, true_labels, normalized\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m train_loss \u001B[38;5;241m/\u001B[39m samples_num, train_correct \u001B[38;5;241m/\u001B[39m samples_num\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1057\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "performances = train_model(model,\n",
    "                           data_manager,\n",
    "                           criterion,\n",
    "                           n_epochs=4,\n",
    "                           lr=0.001,\n",
    "                           weight_decay=0.0001\n",
    "                           )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = range(n_epochs)\n",
    "for metric_type, dataset_type_dict in performances.items():\n",
    "    for dataset_type, values in dataset_type_dict.items():\n",
    "        plt.plot(epochs, values, label=dataset_type)\n",
    "    plt.title(f'{metric_type} over training/validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_type)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # predictions for the whole data\n",
    "test_iterator = data_manager.get_torch_iterator(TEST)\n",
    "test_predictions, test_true, test_loss, test_accuracy = get_prediction_for_data(model, test_iterator, criterion)\n",
    "print(f\"Test loss: {np.round(test_loss, 3)} accuracy: {np.round(test_accuracy, 3)} over entire dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test accuracy over negated polarity examples\n",
    "indices = data_loader.get_negated_polarity_examples(data_manager.sentences[TEST])\n",
    "accuracy = binary_accuracy(preds=test_predictions[indices], y=test_true[indices])\n",
    "print(f\"Test accuracy: {np.round(accuracy, 3)} over negated polarity examples\")\n",
    "\n",
    "# test accuracy over rare_words examples\n",
    "indices = data_loader.get_rare_words_examples(data_manager.sentences[TEST], data_manager.sentiment_dataset)\n",
    "accuracy = binary_accuracy(preds=test_predictions[indices], y=test_true[indices])\n",
    "print(f\"Test accuracy: {np.round(accuracy, 3)} over rare words examples\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}